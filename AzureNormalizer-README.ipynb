{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of AzureNormalizer\n",
    "Last edited: April 26, 2021\n",
    "\n",
    "## Description\n",
    "This function was build in support of the BIGIDEAS Lab's Covidentify Project (Duke University). The intention of the function is to extract, transform, and load the unstructured json data from the database that houses the Fitbit and Garmin API pulls into Microsoft Azure's ML Studio. \n",
    "\n",
    "## Background\n",
    "   Because of the nature of Duke's Internal Review Board (IRB), the lab does not have direct control over the API pulls and thus using noSQL was not an option at this time. Without transformation, the json data was unusable to perform any modeling. The entire project was migrated to Azure during the month of Dec 2021, and this package was written to help transform and load the data for use in a Covid detection model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to import the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AzureNormalizer import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding your personal credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from azureml.core.authentication import ServicePrincipalAuthentication\n",
    "\n",
    "#read ini file\n",
    "config = configparser.ConfigParser()\n",
    "config_filepath = 'workspace_config/cfg.ini'\n",
    "config.read(config_filepath)\n",
    "\n",
    "# svc_cfg = config['ServicePrincipalAuthentication']\n",
    "ws_cfg = config['Azure_Workspace']\n",
    "\n",
    "# svc_pr = ServicePrincipalAuthentication(\n",
    "#     tenant_id = svc_cfg['tenant_id'],\n",
    "#     service_principal_id = svc_cfg['service_principal_id'],\n",
    "#     service_principal_password = svc_cfg['service_principal_password']\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data from a Azure Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# azureml-core of version 1.0.72 or higher is required\n",
    "# azureml-dataprep[pandas] of version 1.1.34 or higher is required\n",
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "workspace = Workspace(\n",
    "        subscription_id = ws_cfg['subscription_id'],\n",
    "        resource_group = ws_cfg['resource_group'],\n",
    "        workspace_name = ws_cfg['workspace_name'],\n",
    "#         auth= svc_pr\n",
    "    )\n",
    "dataset = Dataset.get_by_name(workspace, name='covid_participant_positive')\n",
    "\n",
    "### OPTIONAL: the function can be used with an Azure Dataset or with a pandas DataFrame (pandas is recommended) ###\n",
    "df = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the <code>AzureNormalizer</code> package there are two functions: \n",
    "* the main <code>json_normalizer</code> function: performs the transformation and loading work\n",
    "* <code>whichPromptNames</code> function: provides a list of possible prompt names for the user to look at and iterate over\n",
    " \n",
    "A demo of the functionality is shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo of <code>whichPromptNames</code>\n",
    "\n",
    "From <code>whichPromptNames</code>'s documentation:\n",
    ">This function is to help users identify which prompt names are available in json_normalizer function. This is manually inputted and if new prompt names are added, this needs to be updated.\n",
    ">\n",
    ">**INPUTS**<br>\n",
    "><code>device</code>: either \"garmin\" or \"fitbit\".<br>\n",
    "><code>timePeriod</code>: Either \"historical\" or \"current\". When users enrolled into study, their \"historical\" data was shared, \"current\" data is collected and uploaded to the prompt database.\n",
    ">\n",
    ">**OUTPUTS**<br>\n",
    ">Outputs a list of prompt names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>> garmin, current: ['covid_garmin_activity', 'covid_garmin_daily', 'covid_garmin_epoch', 'covid_garmin_sleep']\n",
      "\n",
      ">>> fitbit, historical: ['covid_fitbit_heart_rate_intraday_backfill', 'covid_fitbit_steps_intraday_backfill', 'covid_fitbit_floors_intraday_backfill', 'covid_fitbit_floors_intraday_backfill', 'covid_fitbit_elevation_intraday_backfill', 'covid_fitbit_distance_intraday_backfill', 'covid_fitbit_calories_intraday_backfill', 'covid_fitbit_sleep_intraday_backfill']\n",
      "\n",
      ">>> fitbit, current: ['heart_rate_intraday', 'sleep', 'calories_intraday', 'distance_intraday', 'elevation_intraday', 'floors_intraday', 'steps_intraday', 'r15_daily_sleep', 'weekly_r15_sleep_api', 'weekly_r15_water_api', 'weekly_r15_food_api']\n"
     ]
    }
   ],
   "source": [
    "# prompt = whichPromptNames(\"garmin\", \"historical\") <- not incorporated yet\n",
    "# print(\">>> garmin, historical:\", prompt)\n",
    "prompt = whichPromptNames(\"garmin\", \"current\")\n",
    "print(\"\\n>>> garmin, current:\", prompt)\n",
    "prompt = whichPromptNames(\"fitbit\", \"historical\")\n",
    "print(\"\\n>>> fitbit, historical:\", prompt)\n",
    "prompt = whichPromptNames(\"fitbit\", \"current\")\n",
    "print(\"\\n>>> fitbit, current:\", prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Using these lists, a user can use a for-loop to iterate over the possible prompt names to quickly generate the needed output datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demo of <code>json_normalizer</code>\n",
    "\n",
    "This code is built off of **Pandas'** <code>json_normalize</code>, but because of the nature of our nested jsons and exisitng relational data, more transformation work had to be incorporated before normalization could occur. Additonally, because each promptName has a different json structure, different keyword arguments needed to be implemented for each promptName to make a process that was generalizable for the entire data.\n",
    "\n",
    "From <code>json_normalizer</code>'s documentation:\n",
    ">This function will extract an Azure Dataset from a Azure Dataset Consume\\\n",
    ">transform the nested json into a relational table and load the transformed\\\n",
    ">table directly into the Azure dataSets Assets list.\n",
    ">\n",
    ">**INPUTS**<br>\n",
    "><code>device</code>: either \"garmin\" or \"fitbit\"<br>\n",
    "><code>timePeriod</code>: Either \"historical\" or \"current\". When users enrolled into study, their \"historical\" data was shared, \"current\" data is collected and uploaded to the prompt database.<br>\n",
    "><code>promptName</code>: name of the type of data collected.<br>\n",
    "><code>data</code>: dataset from the targeted Azure DataSet Consume.<br>\n",
    "><code>aggSummary</code> (optional): for some garmin promptNames, it makes more sense to display the data in the aggregated summaries form, which is one level above the default summaries.<br>\n",
    "><code>ignoreInputs</code> (optional): if turned on, skips the default user inputs.<br>\n",
    "><code>prefix</code> (optional): used in conjunction when 'ignoreInputs' is turned on to set the uploaded filename's prefix.<br>\n",
    "><code>pandas</code> (optional): Allows using a pandas dataFrame instead of using a Azure dataset. There is a performance boost when converting to a pandas dataFrame outside of the function.<br>\n",
    ">\n",
    ">**OUTPUTS**<br>\n",
    ">Automatically uploads the transformed data into the Azure dataSets Assets list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### json_normalizer, Demo 1: Running the function from a Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> The shape of the output dataframe is:  (135, 7)\n",
      ">>> The number of rows that did not have data are: 0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want see a sample? [y/n] y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    sleep captured_at  summary.totalMinutesAsleep  summary.totalSleepRecords  \\\n",
      "9      []  2020-07-24                           0                          0   \n",
      "83     []  2020-11-07                           0                          0   \n",
      "97     []  2020-11-04                           0                          0   \n",
      "79     []  2020-09-28                           0                          0   \n",
      "29     []  2020-08-12                           0                          0   \n",
      "..    ...         ...                         ...                        ...   \n",
      "102    []  2020-10-22                           0                          0   \n",
      "96     []  2020-10-17                           0                          0   \n",
      "134    []  2020-11-28                           0                          0   \n",
      "73     []  2020-09-23                           0                          0   \n",
      "110    []  2020-10-30                           0                          0   \n",
      "\n",
      "     summary.totalTimeInBed  uniqueRowID  participant_id  \n",
      "9                         0      1374480            9032  \n",
      "83                        0      2799374            9032  \n",
      "97                        0      2765968            9032  \n",
      "79                        0      2273846            9032  \n",
      "29                        0      1622525            9032  \n",
      "..                      ...          ...             ...  \n",
      "102                       0      2606724            9032  \n",
      "96                        0      2543404            9032  \n",
      "134                       0      2998023            9032  \n",
      "73                        0      2204390            9032  \n",
      "110                       0      2708480            9032  \n",
      "\n",
      "[1350 rows x 7 columns]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to upload? [y/n] y\n",
      "What do you want the prefix for the file to be? demo\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Starting upload...\n",
      "./output_csv/demo-sleep.csv\n",
      "Uploading an estimated of 1 files\n",
      "Uploading ./output_csv/demo-sleep.csv\n",
      "Uploaded ./output_csv/demo-sleep.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n",
      ">>> Upload Successful!\n"
     ]
    }
   ],
   "source": [
    "json_normalizer(\"fitbit\", \"current\", prompt[1], data=df, pandas=True, pipeline=False, workspace=workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Notice that there are user input options above. These user inputs are:**<br>\n",
    ">   1. Seeing a random sample of 10 lines of the data before uploading. If there are less than 10 lines, the data will be randomly repeated.\n",
    ">   2. An option to upload the data.\n",
    ">   3. If uploading, a prefix can be designated to help distinguish the source of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Below is a screenshot of Azure's ML Studio to show where the dataset ends up:**<br>\n",
    "\n",
    "<center><img src=\"./assets/dataset_in_MLPortal.png\" alt=\"Dataset location in portal\" style=\"width: 1000px;\"/></center>\n",
    "\n",
    "> **This screenshot shows that the code auto-generates the description with the input info:**<br>\n",
    "\n",
    "<center><img src=\"./assets/dataset_description.png\" alt=\"Dataset description\" style=\"width: 1000px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### json_normalizer, Demo 2: What happens if you try to use the wrong inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No data in output dataframe. Check inputs.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-bfb5477f3a39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjson_normalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"fitbit\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"historical\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/jch122-vm01/code/Users/jch122/20_transform_script/AzureNormalizer/json_normalizer.py\u001b[0m in \u001b[0;36mjson_normalizer\u001b[0;34m(device, timePeriod, promptName, data, workspace, aggSummary, ignoreInputs, prefix, pandas, pipeline)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# dealing with no data in output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No data in output dataframe. Check inputs.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">>> The shape of the output dataframe is: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No data in output dataframe. Check inputs."
     ]
    }
   ],
   "source": [
    "json_normalizer(\"fitbit\", \"historical\", prompt[1], data=df, pandas=True, workspace=workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom exception was added for when a the data outputs a dataframe shape of (0,0). If the the entire dataframe has no data, most likely the inputs are incorrect. In the case above, prompt[1] was from the <code>fitbit</code> <code>current</code> list, so the promptname  <code>'covid_fitbit_steps_intraday_backfill'</code> could not be found in the appropriate keyword-argument list to run <code>json_normalize</code>.\n",
    "\n",
    "However, there are times when the data has missing rows for specific datasets and can handle a some missing data. See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> The shape of the output dataframe is:  (217540, 9)\n",
      ">>> The number of rows that did not have data are: 11\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want see a sample? [y/n] y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        hRZ-max  hRZ-min      hRZ-name  hRZ-minutes  hRZ-caloriesOut  \\\n",
      "5529        115       99      Fat Burn          5.0         22.69170   \n",
      "160794      126      104        Cardio         10.0         35.26236   \n",
      "95097       104       74      Fat Burn        941.0        884.27764   \n",
      "72546       125      103        Cardio          1.0          3.66252   \n",
      "68615       220      125          Peak          0.0          0.00000   \n",
      "...         ...      ...           ...          ...              ...   \n",
      "11037       103       74      Fat Burn        916.0        897.47664   \n",
      "54330       126      104        Cardio          0.0          0.00000   \n",
      "153064       74       30  Out of Range        411.0        334.16514   \n",
      "166268       98       30  Out of Range       1440.0       1146.52800   \n",
      "29646       125      103        Cardio          1.0          3.18480   \n",
      "\n",
      "       captured_at.dateTime activities-heart.value.restingHeartRate  \\\n",
      "5529             2020-10-23                                      67   \n",
      "160794           2019-11-17                                      70   \n",
      "95097            2019-09-27                                      72   \n",
      "72546            2020-04-06                                      65   \n",
      "68615            2020-07-22                                      71   \n",
      "...                     ...                                     ...   \n",
      "11037            2020-07-30                                      71   \n",
      "54330            2019-09-25                                      69   \n",
      "153064           2020-07-22                                      71   \n",
      "166268           2020-10-27                                     NaN   \n",
      "29646            2020-05-26                                      69   \n",
      "\n",
      "        uniqueRowID  participant_id  \n",
      "5529        3415772            9032  \n",
      "160794      2292425            9032  \n",
      "95097       1567230            9032  \n",
      "72546       1434032            9032  \n",
      "68615       1378136            9032  \n",
      "...             ...             ...  \n",
      "11037       3400500            9032  \n",
      "54330       1243760            9032  \n",
      "153064      2162730            9032  \n",
      "166268      3121012            9032  \n",
      "29646       3645948            9032  \n",
      "\n",
      "[2175400 rows x 9 columns]\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to upload? [y/n] n\n"
     ]
    }
   ],
   "source": [
    "json_normalizer(\"fitbit\", \"historical\", \"covid_fitbit_heart_rate_intraday_backfill\", data=df, pandas=True, workspace=workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### json_normalizer, Demo 3: What is aggSummary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some promptNames, especially the Garmin promptNames, there is a aggregated summary that encasulates the entire observation period, and a nested summary that captures more granular observation periods. To illustrate this, the json structure of the promptName <code>covid_garmin_activity</code> for the 'current' <code>timePeriod</code> is shown below. <code>Summary</code> is highlighted in green and <code>aggregatedSummary</code> is highlighted in purple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"./assets/summaryAggSummary_compare.png\" alt=\"Comparision of Summary and AggSummary\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this dataset, an output for a single line would look like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <code>aggregatedSummary</code> of covid_garmin_activity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activities</th>\n",
       "      <th>captured_at</th>\n",
       "      <th>aggregatedSummary.durationInSeconds</th>\n",
       "      <th>aggregatedSummary.averageHeartRateInBeatsPerMinute</th>\n",
       "      <th>aggregatedSummary.distanceInMeters</th>\n",
       "      <th>aggregatedSummary.steps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[{'summaryId': '5133495146-detail', 'summary':...</td>\n",
       "      <td>2020-06-23</td>\n",
       "      <td>2402</td>\n",
       "      <td>135</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          activities captured_at  \\\n",
       "0  [{'summaryId': '5133495146-detail', 'summary':...  2020-06-23   \n",
       "\n",
       "   aggregatedSummary.durationInSeconds  \\\n",
       "0                                 2402   \n",
       "\n",
       "   aggregatedSummary.averageHeartRateInBeatsPerMinute  \\\n",
       "0                                                135    \n",
       "\n",
       "   aggregatedSummary.distanceInMeters  aggregatedSummary.steps  \n",
       "0                                   0                        0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pandas import json_normalize\n",
    "import json\n",
    "\n",
    "promptValue = \"covid_garmin_activity\"\n",
    "chars = '\"'\n",
    "subsetForTransformation = df[(df.prompt_name == promptValue)]\n",
    "\n",
    "pd_current_json_value = pd.DataFrame(json_normalize(data=json.loads(subsetForTransformation[\"json_value\"].iloc[93].replace(\"\\\\\",\"\").strip(chars)),))\n",
    "\n",
    "pd_current_json_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <code>Summary</code> of covid_garmin_activity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summaryId</th>\n",
       "      <th>samples</th>\n",
       "      <th>laps</th>\n",
       "      <th>summary.durationInSeconds</th>\n",
       "      <th>summary.startTimeInSeconds</th>\n",
       "      <th>summary.startTimeOffsetInSeconds</th>\n",
       "      <th>summary.activityType</th>\n",
       "      <th>summary.averageHeartRateInBeatsPerMinute</th>\n",
       "      <th>summary.activeKilocalories</th>\n",
       "      <th>summary.deviceName</th>\n",
       "      <th>summary.maxHeartRateInBeatsPerMinute</th>\n",
       "      <th>captured_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5133495146-detail</td>\n",
       "      <td>[{'startTimeInSeconds': 1592924840, 'elevation...</td>\n",
       "      <td>[{'startTimeInSeconds': 1592924840}]</td>\n",
       "      <td>2402</td>\n",
       "      <td>1592924840</td>\n",
       "      <td>3600</td>\n",
       "      <td>INDOOR_CARDIO</td>\n",
       "      <td>135</td>\n",
       "      <td>387</td>\n",
       "      <td>vivoactive3</td>\n",
       "      <td>175</td>\n",
       "      <td>2020-06-23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           summaryId                                            samples  \\\n",
       "0  5133495146-detail  [{'startTimeInSeconds': 1592924840, 'elevation...   \n",
       "\n",
       "                                   laps  summary.durationInSeconds  \\\n",
       "0  [{'startTimeInSeconds': 1592924840}]                       2402   \n",
       "\n",
       "   summary.startTimeInSeconds  summary.startTimeOffsetInSeconds  \\\n",
       "0                  1592924840                              3600   \n",
       "\n",
       "  summary.activityType  summary.averageHeartRateInBeatsPerMinute  \\\n",
       "0        INDOOR_CARDIO                                       135   \n",
       "\n",
       "   summary.activeKilocalories summary.deviceName  \\\n",
       "0                         387        vivoactive3   \n",
       "\n",
       "   summary.maxHeartRateInBeatsPerMinute captured_at  \n",
       "0                                   175  2020-06-23  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd_current_json_value = pd.DataFrame(json_normalize(\n",
    "                                        data=json.loads(subsetForTransformation[\"json_value\"].iloc[93].replace(\"\\\\\",\"\").strip(chars)),\n",
    "                                        record_path =  \"activities\", meta =  \"captured_at\",))\n",
    "pd_current_json_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason that this option exists is that for some promptNames, it makes more sense to use the aggregatedSummary compared to looking at the underlying data. An example of this is if you wanted the step count of an entire day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### json_normalizer, Demo 4: Ignoring Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a user wants to iterate over a list prompt names, one may want to turn off the [y/n] user inputs. To do so, set <code>ignoreInputs</code> to <code>True</code>. Normally, one would still want to set the desired prefix of the filepath. Thus, input the desired prefix into <code>prefix</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is demonstrated below on all the promptNames in Garmin in the <code>current</code> time period (Note: promptName <code>covid_garmin_daily</code>  may take a while to run)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>The prompt name is: covid_garmin_activity\n",
      ">>> The shape of the output dataframe is:  (143, 28)\n",
      ">>> The number of rows that did not have data are: 0\n",
      ">>> Starting upload...\n",
      "./output_csv/demo_2-covid_garmin_activity.csv\n",
      "Uploading an estimated of 1 files\n",
      "Uploading ./output_csv/demo_2-covid_garmin_activity.csv\n",
      "Uploaded ./output_csv/demo_2-covid_garmin_activity.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n",
      ">>> Upload Successful!\n",
      "\n",
      ">>>The prompt name is: covid_garmin_daily\n",
      ">>> The shape of the output dataframe is:  (4661, 35)\n",
      ">>> The number of rows that did not have data are: 0\n",
      ">>> Starting upload...\n",
      "./output_csv/demo_2-covid_garmin_daily.csv\n",
      "Uploading an estimated of 1 files\n",
      "Uploading ./output_csv/demo_2-covid_garmin_daily.csv\n",
      "Uploaded ./output_csv/demo_2-covid_garmin_daily.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n",
      ">>> Upload Successful!\n",
      "\n",
      ">>>The prompt name is: covid_garmin_epoch\n",
      ">>> The shape of the output dataframe is:  (18431, 16)\n",
      ">>> The number of rows that did not have data are: 0\n",
      ">>> Starting upload...\n",
      "./output_csv/demo_2-covid_garmin_epoch.csv\n",
      "Uploading an estimated of 1 files\n",
      "Uploading ./output_csv/demo_2-covid_garmin_epoch.csv\n",
      "Uploaded ./output_csv/demo_2-covid_garmin_epoch.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n",
      ">>> Upload Successful!\n",
      "\n",
      ">>>The prompt name is: covid_garmin_sleep\n",
      ">>> The shape of the output dataframe is:  (2349, 19)\n",
      ">>> The number of rows that did not have data are: 0\n",
      ">>> Starting upload...\n",
      "./output_csv/demo_2-covid_garmin_sleep.csv\n",
      "Uploading an estimated of 1 files\n",
      "Uploading ./output_csv/demo_2-covid_garmin_sleep.csv\n",
      "Uploaded ./output_csv/demo_2-covid_garmin_sleep.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n",
      ">>> Upload Successful!\n"
     ]
    }
   ],
   "source": [
    "prompt = whichPromptNames(\"garmin\", \"current\")\n",
    "#print(\"\\n>>> garmin, current:\", prompt)\n",
    "for pmt in prompt:\n",
    "    print(f\"\\n>>>The prompt name is: {pmt}\")\n",
    "    json_normalizer(\"garmin\", \"current\", pmt, data=df, pandas=True, ignoreInputs=True, prefix=\"demo_2\", workspace=workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"./assets/listOfGarminDatasets.png\" alt=\"Comparision of Summary and AggSummary\" style=\"width: 600px;\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### json_normalizer, Demo 5: Azure Dataset versus Pandas DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although <code>json_normalizer</code> can use Azure Datasets, it is advised to use a pandas dataframe instead because the time it takes to run using an Azure Dataset is much greater than a pandas dataframe. See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> The shape of the output dataframe is:  (58400, 4)\n",
      ">>> The number of rows that did not have data are: 0\n",
      ">>> Starting upload...\n",
      "./output_csv/demo_3-covid_fitbit_steps_intraday_backfill.csv\n",
      "Uploading an estimated of 1 files\n",
      "Uploading ./output_csv/demo_3-covid_fitbit_steps_intraday_backfill.csv\n",
      "Uploaded ./output_csv/demo_3-covid_fitbit_steps_intraday_backfill.csv, 1 files out of an estimated total of 1\n",
      "Uploaded 1 files\n",
      ">>> Upload Successful!\n",
      "Time ellapsed: 52.95737 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "json_normalizer(\"fitbit\", \"historical\", \"covid_fitbit_steps_intraday_backfill\", data=dataset,  ignoreInputs=True, prefix=\"demo_3\", pandas=False, workspace=workspace)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Time ellapsed: {end - start:.5f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> The shape of the output dataframe is:  (58400, 4)\n",
      ">>> The number of rows that did not have data are: 0\n",
      ">>> Starting upload...\n",
      ">>> Upload Successful!\n",
      "Time ellapsed: 2.69776 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "json_normalizer(\"fitbit\", \"historical\", \"covid_fitbit_steps_intraday_backfill\", data=df,  ignoreInputs=True, prefix=\"demo_3\", pandas=True, workspace=workspace)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f\"Time ellapsed: {end - start:.5f} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
